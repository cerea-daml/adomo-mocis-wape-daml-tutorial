{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33e0fe0",
   "metadata": {},
   "source": [
    "# Data assimilation and deep learning applied to a shallow water model: advanced questions\n",
    "\n",
    "##### Sibo Cheng, CEREA, ENPC, [sibo.cheng@enpc.fr](mailto:sibo.cheng@enpc.fr)\n",
    "\n",
    "In this notebook, you will train a deep learning surrogate model for the shallow water system and perform variational data assimilation using neural networks for parameter calibration.\n",
    "\n",
    "This notebook is NOT MONDATORY for the evaluation!\n",
    "\n",
    "# I. A deep learning surrogate model\n",
    "\n",
    "Physics simulations can be time-consuming; training a surrogate (meta-)model to learn from data generated by a physics-based code is widely used to accelerate predictions. \n",
    "\n",
    "You will be asked to train a surrogate model of the shallow water system with initial conditions Q (inflow), g (gravity coefficient),h (initial water level) as input, with the full h and u fields at time step 100 as outputs   \n",
    "\n",
    "# II. Data assimilation for parameter calibration\n",
    "\n",
    "You fully observe the h and u fields at at time step 100 and you would like to identify the initial conditions Q,g,h with the help of the surrogate model in I. You can use the average value of these parameters as an initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa32586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shallow_water_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859f66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db590a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = 100\n",
    "dx = 1.0\n",
    "dt = 0.03\n",
    "Nt_target = 100  # we want h and u at time index 100\n",
    "\n",
    "def simulate_shallow_water(Q, g, h_anom):\n",
    "    \"\"\"\n",
    "    Run the shallow water model for Nt_target steps with given (Q, g, h_anom)\n",
    "    and return h(x, t=Nt_target), u(x, t=Nt_target).\n",
    "    \"\"\"\n",
    "    model = ShallowWaterModel(Nx=Nx, dx=dx, dt=dt, Q=Q, g=g)\n",
    "    state = model.new_state_crenel(h_anom=h_anom)\n",
    "\n",
    "    for _ in range(Nt_target):\n",
    "        model.forward(state)\n",
    "\n",
    "    # Copy to avoid side-effects\n",
    "    h_final = state.h.copy()\n",
    "    u_final = state.u.copy()\n",
    "    return h_final, u_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb4dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of different parameters\n",
    "Q_min, Q_max = 0.05, 0.20\n",
    "g_min, g_max = 9.5, 10.5\n",
    "h_min, h_max = 1.02, 1.15\n",
    "\n",
    "def sample_parameters(batch_size=1):\n",
    "\n",
    "    Q = np.random.uniform(Q_min, Q_max, size=batch_size)\n",
    "    g = np.random.uniform(g_min, g_max, size=batch_size)\n",
    "    h_anom = np.random.uniform(h_min, h_max, size=batch_size)\n",
    "    return Q, g, h_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419af7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of the input and output data for your neural network\n",
    "\n",
    "Q_ex, g_ex, h_anom_ex = sample_parameters()\n",
    "\n",
    "print('inputs q,g,h: ', Q_ex, g_ex, h_anom_ex) \n",
    "\n",
    "h,u = simulate_shallow_water(Q_ex[0], g_ex[0], h_anom_ex[0]) \n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.plot(u, label=\"u\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Velocity u(x, t = 100)\")\n",
    "plt.title(\"NN output u (x, t=100)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(h, label=\"h\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Velocity h(x, t = 100)\")\n",
    "plt.title(\"NN output h (x, t=100)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf4d58",
   "metadata": {},
   "source": [
    "# Design your neural network and training strategy\n",
    "# Questions\n",
    "1. Design your own neural network and loss function for the surrogate model\n",
    "2. Evaluate the performance within and outside the parameter range of the training data. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the input as q,g,h and output as the concatenation of u(x,t=100) and h(x,t=100)\n",
    "\n",
    "#TODO #define the input and output dimension\n",
    "input_dim = \n",
    "output_dim = 2 * \n",
    "\n",
    "#TODO define your MLP neural network\n",
    "\n",
    "class ParamToStateNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        'create your neural network'\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "model_nn = ParamToStateNet().to(device)\n",
    "optimizer = optim.Adam(model_nn.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss() # a mse loss calculated using the model output and groundtruth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de65e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We normalize the input data so that all three inputs are in the same range to help backpropagation\n",
    "# Precompute midpoints and half-ranges for normalization (both in numpy and pytorch)\n",
    "Q_mid, Q_half = (Q_min + Q_max)/2.0, (Q_max - Q_min)/2.0\n",
    "g_mid, g_half = (g_min + g_max)/2.0, (g_max - g_min)/2.0\n",
    "h_mid, h_half = (h_min + h_max)/2.0, (h_max - h_min)/2.0\n",
    "\n",
    "def normalize_params(Q, g, h_anom):\n",
    "    \"\"\"\n",
    "    Map (Q, g, h_anom) to approximately [-1, 1] using the known ranges.\n",
    "    \"\"\"\n",
    "    Qn = (Q - Q_mid) / Q_half\n",
    "    gn = (g - g_mid) / g_half\n",
    "    hn = (h_anom - h_mid) / h_half\n",
    "    return np.stack([Qn, gn, hn], axis=-1).astype(np.float32)\n",
    "\n",
    "def normalize_params_torch(Q, g, h_anom):\n",
    "    \"\"\"\n",
    "    Map (Q, g, h_anom) to approximately [-1, 1] using the known ranges.\n",
    "    \"\"\"\n",
    "    Qn = (Q - Q_mid) / Q_half\n",
    "    gn = (g - g_mid) / g_half\n",
    "    hn = (h_anom - h_mid) / h_half\n",
    "    return torch.stack([Qn, gn, hn], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431438ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10000 #how many iterations of minimization  \n",
    "batch_size = 32 #number of data samples (input-output pairs to be considered in one minization step)   \n",
    "training_loss = []\n",
    "\n",
    "for epoch in range(0, num_epoch):\n",
    "    # Sample parameters\n",
    "    Q_batch, g_batch, h_batch = sample_parameters(batch_size=batch_size)\n",
    "\n",
    "    # run simulations and build targets \n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for Q_i, g_i, h_i in zip(Q_batch, g_batch, h_batch):\n",
    "        h_final, u_final = simulate_shallow_water(Q_i, g_i, h_i)\n",
    "        \n",
    "        target = np.concatenate([h_final, u_final])  # shape (2*Nx,)\n",
    "\n",
    "        x_i = normalize_params(Q_i, g_i, h_i)        # shape (3,)\n",
    "        \n",
    "        inputs.append(x_i)\n",
    "        targets.append(target.astype(np.float32))\n",
    "\n",
    "    inputs = torch.tensor(np.stack(inputs, axis=0), device=device)    # (B, 3)\n",
    "    targets = torch.tensor(np.stack(targets, axis=0), device=device)  # (B, 2*Nx)\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #TODO compute the model prediction and the training loss\n",
    "    preds = \n",
    "    loss = \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    training_loss.append(loss.item())\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}/{num_epoch}, loss = {loss.item():.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a77666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the evolution of the loss function\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_loss, label=\"training loss value\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"training epochs\")\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849c561",
   "metadata": {},
   "source": [
    "# Evaluate the prediction performance on unseen parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2952e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO change the reference parameters within and without the definition range of the training data, what can you observe?\n",
    "# Reference parameters\n",
    "\n",
    "Q_ref = 0.06 #these are by default test values\n",
    "g_ref = 10.1\n",
    "h_anom_ref = 1.01\n",
    "\n",
    "# simulation output as ground truth\n",
    "h_true, u_true = simulate_shallow_water(Q_ref, g_ref, h_anom_ref)\n",
    "\n",
    "# NN prediction\n",
    "x_ref = normalize_params(Q_ref, g_ref, h_anom_ref)[None, ...]   # shape (1, 3)\n",
    "\n",
    "x_ref_t = torch.tensor(x_ref, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model_nn(x_ref_t).cpu().numpy()[0]  # (2*Nx,)\n",
    "\n",
    "h_pred = y_pred[:Nx]\n",
    "u_pred = y_pred[Nx:]\n",
    "\n",
    "\n",
    "x_grid = np.arange(Nx) * dx\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_grid, h_true, label=\"True h\", linewidth=2)\n",
    "plt.plot(x_grid, h_pred, \"--\", label=\"NN surrogate h\",  color='red',linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "#plt.ylabel(\"h(x, t=100)\")\n",
    "plt.title(\"Water height at t=100\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_grid, u_true, label=\"True u\", linewidth=2)\n",
    "plt.plot(x_grid, u_pred, \"--\", label=\"NN surrogate u\", color='red',linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "#plt.ylabel(\"u(x, t=100)\")\n",
    "plt.title(\"Velocity at t=100\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84dea0b",
   "metadata": {},
   "source": [
    "# Data assimilation for parameter identification\n",
    "You will use the built surrogate model to identify the parameters from observed curves $u(x,t=100)$ and $h(x,t=100)$\n",
    "\n",
    "The 3Dvar with NN transformation function will be performed using the TorchDA package\n",
    "\n",
    "pip3 install git+https://github.com/acse-jm122/torchda.git\n",
    "\n",
    "# Questions\n",
    "1. Compute a 3D-Var for parameter calibration using the TorchDA package\n",
    "2. Why some parameters are better corrected than the others? you can run some simulations to confirm your answer\n",
    "3. Can you do an assimilation with partial observations (not fully observed h and v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73588b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d228d42",
   "metadata": {},
   "source": [
    "We will perform a twin experiment: (i) fix some parameter values and run the simulation (ii) see if the DA system could identify those parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a43c5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix parameter values (the true value of parameters)\n",
    "Q_true = 0.06\n",
    "g_true = 10.2\n",
    "h_anom_true = 1.01\n",
    "\n",
    "# True simulation\n",
    "h_true, u_true = simulate_shallow_water(Q_ref, g_ref, h_anom_ref)\n",
    "\n",
    "y_true = np.concatenate((h_true,u_true),axis=0)\n",
    "\n",
    "y = torch.from_numpy(y_true).float().to(device)\n",
    "\n",
    "\n",
    "# prior (background) parameters: this is our initial guess\n",
    "Q_prior = 0.08\n",
    "g_prior = 9.7\n",
    "h_anom_prior = 1.05\n",
    "\n",
    "xb = torch.tensor([Q_prior, g_prior, h_anom_prior]).to(device).requires_grad_(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchda\n",
    "\n",
    "# set covariance matrices\n",
    "B = torch.eye(3, device=device)\n",
    "R = 0.01*torch.eye(200, device=device)\n",
    "\n",
    "#TODO define the transformation function H using the trained NN model\n",
    "def H(x: torch.Tensor):\n",
    "    \n",
    "    y_pred = \n",
    "        \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "#TODO set the background state and the observation\n",
    "\n",
    "results_3dvar = torchda.CaseBuilder().set_background_covariance_matrix(\n",
    "    B\n",
    ").set_observation_covariance_matrix(R).set_observations(\n",
    "    'what is your observation?'\n",
    ").set_background_state(\n",
    "    'what is your background state?'\n",
    ").set_algorithm(\n",
    "    torchda.Algorithms.Var3D\n",
    ").set_device(\n",
    "    torchda.Device.GPU\n",
    ").set_optimizer_args(\n",
    "    {\"lr\": 1e-3}\n",
    ").set_max_iterations(\n",
    "    500\n",
    ").set_observation_model(\n",
    "    H\n",
    ").execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114cdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assimilated parameters\n",
    "Q_ass = results_3dvar['assimilated_state'].detach().cpu().numpy()[0]\n",
    "g_ass = results_3dvar['assimilated_state'].detach().cpu().numpy()[1]\n",
    "h_anom_ass = results_3dvar['assimilated_state'].detach().cpu().numpy()[2]\n",
    "\n",
    "\n",
    "# assimilated simulation\n",
    "h_ass, u_ass = simulate_shallow_water(Q_ass, g_ass, h_anom_ass)\n",
    "\n",
    "\n",
    "# background simulation\n",
    "h_prior, u_prior = simulate_shallow_water(Q_prior, g_prior, h_anom_prior)\n",
    "\n",
    "# NN prediction with assimilated parameters\n",
    "x_ref = normalize_params(Q_ass, g_ass, h_anom_ass)[None, ...]   # shape (1, 3)\n",
    "x_ref_t = torch.tensor(x_ref, device=device)\n",
    "with torch.no_grad():\n",
    "    y_pred = model_nn(x_ref_t).cpu().numpy()[0]  # (2*Nx,)\n",
    "h_pred = y_pred[:Nx]\n",
    "u_pred = y_pred[Nx:]\n",
    "\n",
    "x_grid = np.arange(Nx) \n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_grid, h_true, label=\"True h simulation\", linewidth=2)\n",
    "plt.plot(x_grid, h_ass, label=\"DA h simulation\",  color='red',linewidth=2)\n",
    "plt.plot(x_grid, h_pred, '--', label=\"DA h prediction\",  color='red',linewidth=2)\n",
    "plt.plot(x_grid, h_prior, label=\"prior h simulation\",  color='green',linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"h(x, t=100)\")\n",
    "plt.title(\"Water height at t=100\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_grid, u_true, label=\"True u simulation\", linewidth=2)\n",
    "plt.plot(x_grid, u_ass, label=\"DA u simulation\", color='red',linewidth=2)\n",
    "plt.plot(x_grid, u_pred, '--', label=\"DA u prediction\",  color='red',linewidth=2)\n",
    "plt.plot(x_grid, u_prior, label=\"prior u simulation\",  color='green',linewidth=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"u(x, t=100)\")\n",
    "plt.title(\"Velocity at t=100\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True parameters of Q, g, h: ', Q_true, g_true, h_anom_true)\n",
    "\n",
    "print('Assimilated parameters of Q, g, h: ', Q_ass, g_ass, h_anom_ass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d18a6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
